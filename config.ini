[BASEPATH]
image_data = /home/xilini/vis-data/
densecap_path = /home/xilini/par-data/densecap-reworked/
models_save = /home/xilini/par-gen/01-par-gen/model/checkpoints/
data_folder = /home/xilini/par-gen/01-par-gen/data/
data_folder_densecap = /home/xilini/par-gen/01-par-gen/densecap_processed/

data_name = 6_sent_1_min_word
#vg_6_sent_per_img_5_min_word_freq_NEWdensecap
#vg_6_sent_per_img_5_min_word_freq_20obj_densecap
# SINGLE (vg_1), PRETRAINED (when using densecap pretrained)
#data_name = vg_6_sent_per_img_3_min_word_freqresnet512

[PARAMS-SENTENCE]
hidden_size = 512
num_layers_sentencernn = 1
pooling_dim = 512
resnet512_feat_dim = 2048
densecap_feat_dim = 4096
eos_classes = 2
sentence_decoder_lr = 1e-3
lambda_sentence = 1.0
sent_grad_clip = 0.25
#sentence_weight_decay = 1e-4
sentence_weight_decay = 1e-3
sentence_nonlin = no
use_fc = no
use_fc2 = no

[PARAMS-WORD]
hidden_size = 512
embed_dim = 512
num_layers_wordrnn = 1
max_sentences = 6
max_words = 50
word_decoder_lr = 1e-3
lambda_word = 1.0
word_grad_clip = 1.
#word_weight_decay = 1e-4
word_weight_decay = 1e-3
wordlstm_dropout = 5e-1
word_dropout = 0
topic_hidden = no

[PARAMS-MODELS]
batch_size = 64
#encoder_type = resnet512
encoder_type = densecap
encoder_weight_decay = 0
num_boxes = 50
rnn_hidden_init = zero
embeddings_pretrained = no
freeze = no
rnn_arch = LSTM
start_epoch = 0
num_epochs = 100
workers = 0
encoder_lr = 1e-3
encoder_dropout = 0
dropout_fc = 0
dropout_stopping = 0
print_freq = 20
checkpoint = no
layer_norm = no
bn = no
clipping = no
feature_linear = yes
with_densecap_captions = no

# vocab_size = 7603
temperature = yes
nucleus_sampling = yes
temperature_value = 0.5
top_n = 40
top_p = 0.95

beam = 2
# beam 3 topk 30, ngram block 2
decoding_strategy = beam
set_size = 0

use_attention = 1
multimodal = 1
exp_num = rnn_pretrained_frozen
model_trained = mult+att+/BEST_checkpoint.pth.tar


[EVAL-SCORES]
best_cider = 0.
best_val_loss = 0.

[COMET]
api_key = 3Q7WqkDikDUL0XwFIA9ukuMea
project_name = paragraph-generation
workspace = nilinykh

@proceedings{DaP-2018-Extended,
	Address = {Gothenburg, Sweden},
	Editor = {Howes, Christine and Dobnik, Simon and Breitholtz, Ellen},
	Month = {February},
	Organization = {University of Gothenburg},
	Publisher = {CLASP, Centre for Language and Studies in Probability and GUPEA},
	Title = {{CLASP} Papers in Computational Linguistics: Dialogue and Perception -- Extended papers from {DaP-2018} Gothenburg},
	Volume = {2},
	Year = {2020},
	Url = {http://hdl.handle.net/2077/63998}}

@article{Agrawal:2017aa,
	Author = {Aishwarya Agrawal and Dhruv Batra and Devi Parikh and Aniruddha Kembhavi},
	Journal = {arXiv},
	Pages = {1--15},
	Title = {Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering},
	Volume = {arXiv:1712.00377 [cs.CV]},
	Year = {2017}}

@book{Deemter:2016aa,
	Address = {Cambridge, Massachusetts and London, England},
	Author = {Deemter, Kees van},
	Publisher = {The MIT Press},
	Title = {Computational models of referring: a study in cognitive science},
	Year = {2016}}
	
@misc{paulus2017deep,
      title={A Deep Reinforced Model for Abstractive Summarization}, 
      author={Romain Paulus and Caiming Xiong and Richard Socher},
      year={2017},
      eprint={1705.04304},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
	
@inproceedings{vanmiltenburg2017,
    title = "Cross-linguistic differences and similarities in image descriptions",
    author = "van Miltenburg, Emiel  and
      Elliott, Desmond  and
      Vossen, Piek",
    booktitle = "Proceedings of the 10th International Conference on Natural Language Generation",
    month = sep,
    year = "2017",
    address = "Santiago de Compostela, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-3503",
    doi = "10.18653/v1/W17-3503",
    pages = "21--30",
    abstract = "Automatic image description systems are commonly trained and evaluated on large image description datasets. Recently, researchers have started to collect such datasets for languages other than English. An unexplored question is how different these datasets are from English and, if there are any differences, what causes them to differ. This paper provides a cross-linguistic comparison of Dutch, English, and German image descriptions. We find that these descriptions are similar in many respects, but the familiarity of crowd workers with the subjects of the images has a noticeable influence on the specificity of the descriptions.",
}
	
@inproceedings{vanderlee2019,
    title = "Best practices for the human evaluation of automatically generated text",
    author = "van der Lee, Chris  and
      Gatt, Albert  and
      van Miltenburg, Emiel  and
      Wubben, Sander  and
      Krahmer, Emiel",
    booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-8643",
    doi = "10.18653/v1/W19-8643",
    pages = "355--368",
    abstract = "Currently, there is little agreement as to how Natural Language Generation (NLG) systems should be evaluated. While there is some agreement regarding automatic metrics, there is a high degree of variation in the way that human evaluation is carried out. This paper provides an overview of how human evaluation is currently conducted, and presents a set of best practices, grounded in the literature. With this paper, we hope to contribute to the quality and consistency of human evaluations in NLG.",
}

@inproceedings{Dobnik:2016ac,
	Address = {New Brunswick, NJ USA},
	Author = {Dobnik, Simon and Kelleher, John D.},
	Booktitle = {JerSem: The 20th Workshop on the Semantics and Pragmatics of Dialogue},
	Editor = {Julie Hunter and Mandy Simons and Matthew Stone},
	Month = {July 16--18},
	Pages = {25--34},
	Title = {A Model for Attention-Driven Judgements in {T}ype {T}heory with {R}ecords},
	Volume = {20},
	Year = {2016},
	Url = {http://semdial.org/anthology/papers/Z/Z16/Z16-3007/}}

@article{Lavie:2004aa,
	Author = {Lavie, Nilli and Hirst, Aleksandra and de Fockert, Jan W and Viding, Essi},
	Journal = {Journal of Experimental Psychology: General},
	Number = {3},
	Pages = {339--354},
	Title = {Load theory of selective attention and cognitive control},
	Volume = {133},
	Year = {2004}}

@inproceedings{Kelleher:2020aa,
	Author = {John D. Kelleher and Dobnik, Simon},
	Booktitle = {{CLASP} Papers in Computational Linguistics: Dialogue and Perception -- Extended papers from {DaP-2018} Gothenburg},
	@Crossref = {DaP-2018-Extended},
	Pages = {41--50},
	Year={2019},
	Title = {Referring to the recently seen: reference and perceptual memory in situated dialogue},
	Url = {http://hdl.handle.net/2077/63998}}

@inproceedings{bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@InProceedings{spacy15,
  author    = {Honnibal, Matthew  and  Johnson, Mark},
  title     = {An Improved Non-monotonic Transition System for Dependency Parsing},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {1373--1378},
  url       = {https://aclweb.org/anthology/D/D15/D15-1162}
}

@INPROCEEDINGS{Shetty2017,
  author={R. {Shetty} and M. {Rohrbach} and L. A. {Hendricks} and M. {Fritz} and B. {Schiele}},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training}, 
  year={2017},
  volume={},
  number={},
  pages={4155-4164},
  doi={10.1109/ICCV.2017.445}}



@article{Vijayakumar2016,
  title={Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models},
  author={Ashwin K. Vijayakumar and Michael Cogswell and R. R. Selvaraju and Q. Sun and Stefan Lee and David J. Crandall and Dhruv Batra},
  journal={ArXiv},
  year={2016},
  volume={abs/1610.02424}
}


@article{Devlin2015,
archivePrefix = {arXiv},
arxivId = {1505.01809},
author = {Devlin, Jacob and Cheng, Hao and Fang, Hao and Gupta, Saurabh and Deng, Li and He, Xiaodong and Zweig, Geoffrey and Mitchell, Margaret},
eprint = {1505.01809},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Devlin et al. - 2015 - Language Models for Image Captioning The Quirks and What Works.pdf:pdf},
month = {may},
journal={arXiv},
volume={arXiv:1505.01809 [cs.CL]},
title = {{Language Models for Image Captioning: The Quirks and What Works}},
url = {http://arxiv.org/abs/1505.01809},
year = {2015}
}


@article{Lindh2018,
archivePrefix = {arXiv},
arxivId = {1812.08126},
author = {Lindh, Annika and Ross, Robert J. and Mahalunkar, Abhijit and Salton, Giancarlo and Kelleher, John D.},
doi = {10.1007/978-3-030-01418-6_18},
eprint = {1812.08126},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Lindh et al. - 2018 - Generating Diverse and Meaningful Captions(2).pdf:pdf},
month = {dec},
title = {{Generating Diverse and Meaningful Captions}},
url = {http://arxiv.org/abs/1812.08126 http://dx.doi.org/10.1007/978-3-030-01418-6{\_}18},
year = {2018},
journal={ICANN 2018},
pages={176-187}
}


@article{VanMiltenburg2018,
author = {van Miltenburg, Emiel and Elliott, Desmond and Vossen, Piek},
file = {:Users/xilini/work/gothenburg/literature/C18-1147.pdf:pdf},
journal = {Proceedings of the 27th International Conference on Computational Linguistics},
pages = {1730--1741},
title = {{Measuring the Diversity of Automatic Image Descriptions}},
url = {https://www.aclweb.org/anthology/C18-1147},
year = {2018}
}

@inproceedings{Zhu2018selfbleu,
author = {Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
title = {Texygen: A Benchmarking Platform for Text Generation Models},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210080},
doi = {10.1145/3209978.3210080},
abstract = {We introduce Texygen, a benchmarking platform to support research on open-domain text generation models. Texygen has not only implemented a majority of text generation models, but also covered a set of metrics that evaluate the diversity, the quality and the consistency of the generated texts. The Texygen platform could help standardize the research on text generation and improve the reproductivity and reliability of future research work in text generation.},
booktitle = {The 41st International ACM SIGIR Conference on Research Development in Information Retrieval},
pages = {1097–1100},
numpages = {4},
keywords = {text generation, evaluation metrics, benchmarking},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}

@inproceedings{lindh_generating_2018,
series = {Lecture {Notes} in {Computer} {Science}},
title = {Generating {Diverse} and {Meaningful} {Captions}},
isbn = {978-3-030-01418-6},
doi = {10.1007/978-3-030-01418-6_18},
language = {en},
booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2018},
publisher = {Springer International Publishing},
author = {Lindh, Annika and Ross, Robert J. and Mahalunkar, Abhijit and Salton, Giancarlo and Kelleher, John D.},
editor = {Kůrková, Věra and Manolopoulos, Yannis and Hammer, Barbara and Iliadis, Lazaros and Maglogiannis, Ilias},
year = {2018},
keywords = {Computer Vision, Contrastive Learning, Deep Learning, Diversity, Image Captioning, Image Retrieval, Machine Learning, MS COCO, Multimodal Training, Natural Language Generation, Natural Language Processing, Neural Networks, Specificity},
pages = {176--187}
}


@misc{devlin2015language,
    title={Language Models for Image Captioning: The Quirks and What Works},
    author={Jacob Devlin and Hao Cheng and Hao Fang and Saurabh Gupta and Li Deng and Xiaodong He and Geoffrey Zweig and Margaret Mitchell},
    year={2015},
    eprint={1505.01809},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Caglayan2016,
archivePrefix = {arXiv},
arxivId = {1609.03976},
author = {Caglayan, Ozan and Barrault, Lo{\"{i}}c and Bougares, Fethi},
eprint = {1609.03976},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Caglayan, Barrault, Bougares - 2016 - Multimodal Attention for Neural Machine Translation.pdf:pdf},
month = {sep},
journal={arXiv},
volume={arXiv:1609.03976 [cs.CL]},
title = {{Multimodal Attention for Neural Machine Translation}},
url = {https://arxiv.org/abs/1609.03976},
year = {2016}
}



@misc{Caglayan2019,
archivePrefix = {arXiv},
arxivId = {1903.08678},
author = {Caglayan, Ozan and Madhyastha, Pranava and Specia, Lucia and Barrault, Lo{\"{i}}c},
booktitle = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
doi = {10.18653/v1/n19-1422},
eprint = {1903.08678},
file = {:Users/xilini/work/gothenburg/literature/N19-1422.pdf:pdf},
isbn = {9781950737130},
pages = {4159--4170},
title = {{Probing the need for visual context in multimodal machine translation}},
url = {https://www.aclweb.org/anthology/N19-1422/},
urldate = {2020-07-14},
volume = {1},
year = {2019}
}


@inproceedings{melas2019,
    title = "Training for Diversity in Image Paragraph Captioning",
    author = "Melas-Kyriazi, Luke  and
      Rush, Alexander  and
      Han, George",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1084",
    doi = "10.18653/v1/D18-1084",
    pages = "757--761",
    abstract = "Image paragraph captioning models aim to produce detailed descriptions of a source image. These models use similar techniques as standard image captioning models, but they have encountered issues in text generation, notably a lack of diversity between sentences, that have limited their effectiveness. In this work, we consider applying sequence-level training for this task. We find that standard self-critical training produces poor results, but when combined with an integrated penalty on trigram repetition produces much more diverse paragraphs. This simple training approach improves on the best result on the Visual Genome paragraph captioning dataset from 16.9 to 30.6 CIDEr, with gains on METEOR and BLEU as well, without requiring any architectural changes.",
}

@article{selfcritical2016,
  title={Self-Critical Sequence Training for Image Captioning},
  author={Steven J. Rennie and E. Marcheret and Youssef Mroueh and J. Ross and V. Goel},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={1179-1195}
}


@INPROCEEDINGS{Lu2016,
  author={J. {Lu} and C. {Xiong} and D. {Parikh} and R. {Socher}},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning}, 
  year={2017},
  volume={},
  number={},
  pages={3242-3250},
  doi={10.1109/CVPR.2017.345}}


@article{Simonyan2014,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={K. Simonyan and Andrew Zisserman},
  journal={CoRR},
  year={2015},
  volume={abs/1409.1556}
}


@article{Xu2015,
archivePrefix = {arXiv},
arxivId = {1511.05234},
author = {Xu, Huijuan and Saenko, Kate},
eprint = {1511.05234},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Xu, Saenko - 2015 - Ask, Attend and Answer Exploring Question-Guided Spatial Attention for Visual Question Answering(2).pdf:pdf},
month = {nov},
title = {{Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering}},
url = {http://arxiv.org/abs/1511.05234},
year = {2015}
}

@inproceedings{kilickaya2017,
    title = "Re-evaluating Automatic Metrics for Image Captioning",
    author = "Kilickaya, Mert  and
      Erdem, Aykut  and
      Ikizler-Cinbis, Nazli  and
      Erdem, Erkut",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-1019",
    pages = "199--209",
    abstract = "The task of generating natural language descriptions from images has received a lot of attention in recent years. Consequently, it is becoming increasingly important to evaluate such image captioning approaches in an automatic manner. In this paper, we provide an in-depth evaluation of the existing image captioning metrics through a series of carefully designed experiments. Moreover, we explore the utilization of the recently proposed Word Mover{'}s Distance (WMD) document metric for the purpose of image captioning. Our findings outline the differences and/or similarities between metrics and their relative robustness by means of extensive correlation, accuracy and distraction based evaluations. Our results also demonstrate that WMD provides strong advantages over other metrics.",
}


@article{deerwester90indexing,
  added-at = {2019-10-11T17:00:01.000+0200},
  author = {Deerwester, S. C. and Dumais, S. T. and Landauer, T. K. and Furnas, G. W. and Harshman, R. A.},
  biburl = {https://www.bibsonomy.org/bibtex/2d034edbdc8923caaceb34cc86b9bc60a/bsc},
  interhash = {c15e0f019b2b967d224e7443100e8ff9},
  intrahash = {d034edbdc8923caaceb34cc86b9bc60a},
  journal = {Journal of the American Society of Information Science},
  key = {deerwester90indexing},
  keywords = {lsa textmining topic-models},
  label = {Indexing by Latent Semantic Analysis},
  number = 6,
  pages = {391-407},
  timestamp = {2019-10-11T17:00:01.000+0200},
  title = {Indexing by Latent Semantic Analysis},
  type = {Article},
  volume = 41,
  year = 1990
}



@misc{wang2019describing,
    title={Describing like humans: on diversity in image captioning},
    author={Qingzhong Wang and Antoni B. Chan},
    year={2019},
    eprint={1903.12020},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{Kusner2015FromWE,
  title={From Word Embeddings To Document Distances},
  author={Matt J. Kusner and Yu Sun and Nicholas I. Kolkin and Kilian Q. Weinberger},
  booktitle={ICML},
  year={2015}
}

@InProceedings{meteor14,
  author    = {Michael Denkowski and Alon Lavie},
  title     = {Meteor Universal: Language Specific Translation Evaluation for Any Target Language},
  booktitle = {Proceedings of the EACL 2014 Workshop on Statistical Machine Translation},
  year      = {2014},
}


@inproceedings{bleu2002,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}


@inproceedings{opennmt2017,
    title = "{O}pen{NMT}: Open-Source Toolkit for Neural Machine Translation",
    author = "Klein, Guillaume  and
      Kim, Yoon  and
      Deng, Yuntian  and
      Senellart, Jean  and
      Rush, Alexander",
    booktitle = "Proceedings of {ACL} 2017, System Demonstrations",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-4012",
    pages = "67--72",
}

@article{adam14,
author = {Kingma, Diederik and Ba, Jimmy},
year = {2014},
month = {12},
pages = {},
title = {Adam: A Method for Stochastic Optimization},
journal = {International Conference on Learning Representations}
}

@misc{luong2015effective,
    title={Effective Approaches to Attention-based Neural Machine Translation},
    author={Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
    year={2015},
    eprint={1508.04025},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{vqaLU16,
archivePrefix = {arXiv},
arxivId = {1606.00061},
author = {Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
eprint = {1606.00061},
file = {:Users/xilini/work/gothenburg/literature/1606.00061.pdf:pdf},
month = {may},
title = {{Hierarchical Question-Image Co-Attention for Visual Question Answering}},
url = {http://arxiv.org/abs/1606.00061},
year = {2016}
}

@inproceedings{Dobnik2016AMF,
  title={A Model for Attention-Driven Judgements in Type Theory with Records},
  author={Simon Dobnik and John D. Kelleher},
  year={2016}
}

@misc{Zarcone2016,
author = {Zarcone, Alessandra and van Schijndel, Marten and Vogels, Jorrig and Demberg, Vera},
booktitle = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2016.00844},
file = {:Users/xilini/work/gothenburg/literature/fpsyg-07-00844.pdf:pdf},
issn = {16641078},
keywords = {Attention,Goals,Language,Predictability,Predictive coding,Relevance,Salience,Surprisal},
title = {{Salience and attention in surprisal-based accounts of language processing}},
year = {2016}
}

@incollection{Ullman87,
  AUTHOR = {S. Ullman},
  TITLE = {Visual Routines},
  YEAR = 1987,
  BOOKTITLE = {Readings in Computer Vision: Issues, Problems, Principles, and Paradigms},
  EDITOR = {M. A. Fischler and O. Firschein},
  PUBLISHER = {Kaufmann},
  ADDRESS = {Los Altos, CA.},
  PAGES = {298-328},
  KEYWORDS = {vision}}
  


@article {Lavie04,
	Title = {Load theory of selective attention and cognitive control},
	Author = {Lavie, Nilli and Hirst, Aleksandra and de Fockert, Jan W and Viding, Essi},
	DOI = {10.1037/0096-3445.133.3.339},
	Number = {3},
	Volume = {133},
	Month = {September},
	Year = {2004},
	Journal = {Journal of experimental psychology. General},
	ISSN = {0096-3445},
	Pages = {339—354},
	URL = {https://doi.org/10.1037/0096-3445.133.3.339},
}


@article{Gatt2017,
archivePrefix = {arXiv},
arxivId = {1703.09902},
author = {Gatt, Albert and Krahmer, Emiel},
eprint = {1703.09902},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Gatt, Krahmer - 2017 - Survey of the State of the Art in Natural Language Generation Core tasks, applications and evaluation.pdf:pdf},
month = {mar},
title = {{Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation}},
journal={Journal of AI Research (JAIR)},
volume={61},
pages={75-170},
url = {https://arxiv.org/abs/1703.09902},
year = {2017}
}

@INPROCEEDINGS{You2016,  author={Q. {You} and H. {Jin} and Z. {Wang} and C. {Fang} and J. {Luo}},  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Image Captioning with Semantic Attention},   year={2016},  volume={},  number={},  pages={4651-4659},  doi={10.1109/CVPR.2016.503}}



@misc{vedantam2014cider,
    title={CIDEr: Consensus-based Image Description Evaluation},
    author={Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
    year={2014},
    eprint={1411.5726},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}


@misc{bernardi2016automatic,
    title={Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures},
    author={Raffaella Bernardi and Ruket Cakici and Desmond Elliott and Aykut Erdem and Erkut Erdem and Nazli Ikizler-Cinbis and Frank Keller and Adrian Muscat and Barbara Plank},
    year={2016},
    eprint={1601.03896},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{lin2014microsoft,
    title={Microsoft COCO: Common Objects in Context},
    author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
    year={2014},
    eprint={1405.0312},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{young-etal-2014-image,
    title = "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
    author = "Young, Peter  and
      Lai, Alice  and
      Hodosh, Micah  and
      Hockenmaier, Julia",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "2",
    year = "2014",
    url = "https://www.aclweb.org/anthology/Q14-1006",
    doi = "10.1162/tacl_a_00166",
    pages = "67--78",
    abstract = "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions.",
}

@misc{chen2015microsoft,
    title={Microsoft COCO Captions: Data Collection and Evaluation Server},
    author={Xinlei Chen and Hao Fang and Tsung-Yi Lin and Ramakrishna Vedantam and Saurabh Gupta and Piotr Dollar and C. Lawrence Zitnick},
    year={2015},
    eprint={1504.00325},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{krishnavisualgenome,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  year = {2016},
  url = {https://arxiv.org/abs/1602.07332},
}

@article{hodosh2013,
author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
title = {Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {853–899},
numpages = {47}
}

@article{Caccia2018,
archivePrefix = {arXiv},
arxivId = {1811.02549},
author = {Caccia, Massimo and Caccia, Lucas and Fedus, William and Larochelle, Hugo and Pineau, Joelle and Charlin, Laurent},
eprint = {1811.02549},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Caccia et al. - 2018 - Language GANs Falling Short.pdf:pdf},
month = {nov},
title = {{Language GANs Falling Short}},
url = {http://arxiv.org/abs/1811.02549},
year = {2018}
}

@article{Holtzman2019,
  title={The Curious Case of Neural Text Degeneration},
  author={Holtzman, Ari and Buys, Jan and Forbes, Maxwell and Choi, Yejin},
  journal={International Conference on Learning Representations},
  year={2020}
}



@misc{vinyals2014tell,
    title={Show and Tell: A Neural Image Caption Generator},
    author={Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan},
    year={2014},
    eprint={1411.4555},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{densecap,
  title={DenseCap: Fully Convolutional Localization Networks for Dense Captioning},
  author={Johnson, Justin and Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and 
             Pattern Recognition},
  year={2016}
}

@misc{holtzman2019curious,
    title={The Curious Case of Neural Text Degeneration},
    author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
    year={2019},
    eprint={1904.09751},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Lin2015,
archivePrefix = {arXiv},
arxivId = {1503.00064},
author = {Lin, Dahua and Kong, Chen and Fidler, Sanja and Urtasun, Raquel},
eprint = {1503.00064},
month = {feb},
title = {{Generating Multi-Sentence Lingual Descriptions of Indoor Scenes}},
url = {https://arxiv.org/abs/1503.00064},
year = {2015},
journal={arXiv},
volume={arXiv:1503.00064 [cs.CV]}
}

@inproceedings{ilinykh19,
    title = "Tell Me More: A Dataset of Visual Scene Description Sequences",
    author = "Ilinykh, Nikolai  and
      Zarrie{\ss}, Sina  and
      Schlangen, David",
    booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-8621",
    doi = "10.18653/v1/W19-8621",
    pages = "152--157",
    abstract = "We present a dataset consisting of what we call image description sequences, which are multi-sentence descriptions of the contents of an image. These descriptions were collected in a pseudo-interactive setting, where the describer was told to describe the given image to a listener who needs to identify the image within a set of images, and who successively asks for more information. As we show, this setup produced nicely structured data that, we think, will be useful for learning models capable of planning and realising such description discourses.",
}


@MISC{Reiter00buildingnatural,
    author = {Ehud Reiter and Robert Dale},
    title = {Building Natural Language Generation Systems},
    year = {2000}
}

@article{grosz95,
    title = "{C}entering: A Framework for Modeling the Local Coherence of Discourse",
    author = "Grosz, Barbara J.  and
      Joshi, Aravind K.  and
      Weinstein, Scott",
    journal = "Computational Linguistics",
    volume = "21",
    number = "2",
    year = "1995",
    url = "https://www.aclweb.org/anthology/J95-2003",
    pages = "203--225",
}


@article{Barzilay2008,
author = {Barzilay, Regina and Lapata, Mirella},
doi = {10.1162/coli.2008.34.1.1},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Barzilay, Lapata - 2008 - Modeling local coherence An entity-based approach.pdf:pdf},
issn = {08912017},
journal = {Computational Linguistics},
number = {1},
pages = {1--34},
title = {{Modeling local coherence: An entity-based approach}},
volume = {34},
year = {2008}
}


@inproceedings{barzilay-lee-2004-catching,
    title = "Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization",
    author = "Barzilay, Regina  and
      Lee, Lillian",
    booktitle = "Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004",
    month = may # " 2 - " # may # " 7",
    year = "2004",
    address = "Boston, Massachusetts, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N04-1015",
    pages = "113--120",
}

@article{Yang2018,
archivePrefix = {arXiv},
arxivId = {1808.09582},
author = {Yang, Yilin and Huang, Liang and Ma, Mingbo},
eprint = {1808.09582},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Yang, Huang, Ma - 2018 - Breaking the Beam Search Curse A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Transla.pdf:pdf},
month = {aug},
title = {{Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation}},
url = {http://arxiv.org/abs/1808.09582},
year = {2018}
}


@misc{wang2019convolutional,
    title={Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation},
    author={Jing Wang and Yingwei Pan and Ting Yao and Jinhui Tang and Tao Mei},
    year={2019},
    eprint={1908.00249},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{liang2017recurrent,
    title={Recurrent Topic-Transition GAN for Visual Paragraph Generation},
    author={Xiaodan Liang and Zhiting Hu and Hao Zhang and Chuang Gan and Eric P. Xing},
    year={2017},
    eprint={1703.07022},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{Cooper08typetheory,
    author = {Robin Cooper},
    title = {Type theory with records and unification-based grammar},
    booktitle = {Logics for Linguistic Structures, pages 9 – 34. Mouton de Gruyter},
    year = {2008}
}

@inproceedings{chatterjee2018diverse,
Author = {Moitreya Chatterjee and Alexander G. Schwing},
Title = {Diverse and Coherent Paragraph Generation from Images},
Year = {2018},
booktitle = {ECCV},
}


@inproceedings{krause2016hierarchical,
  title={A Hierarchical Approach for Generating Descriptive Image Paragraphs},
  author={Krause, Jonathan and Johnson, Justin and Krishna, Ranjay and Fei-Fei, Li},
  booktitle={Computer Vision and Patterm Recognition (CVPR)},
  year={2017}
}

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{herdade2019image,
    title={Image Captioning: Transforming Objects into Words},
    author={Simao Herdade and Armin Kappeler and Kofi Boakye and Joao Soares},
    year={2019},
    eprint={1906.05963},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{anderson2017bottomup,
    title={Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
    author={Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},
    year={2017},
    eprint={1707.07998},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{lstm97,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}
  
@article{beam17,
   title={Beam Search Strategies for Neural Machine Translation},
   url={http://dx.doi.org/10.18653/v1/W17-3207},
   DOI={10.18653/v1/w17-3207},
   journal={Proceedings of the First Workshop on Neural Machine Translation},
   publisher={Association for Computational Linguistics},
   author={Freitag, Markus and Al-Onaizan, Yaser},
   year={2017}
}



@misc{bahdanau2014neural,
    title={Neural Machine Translation by Jointly Learning to Align and Translate},
    author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year={2014},
    eprint={1409.0473},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@misc{xu2015attend,
    title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
    author={Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio},
    year={2015},
    eprint={1502.03044},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@InProceedings{kiros14,
  title = 	 {Multimodal Neural Language Models},
  author = 	 {Ryan Kiros and Ruslan Salakhutdinov and Rich Zemel},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {595--603},
  year = 	 {2014},
  editor = 	 {Eric P. Xing and Tony Jebara},
  volume = 	 {32},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/kiros14.pdf},
  url = 	 {http://proceedings.mlr.press/v32/kiros14.html},
  abstract = 	 {We introduce two multimodal neural language models: models of natural language that can be conditioned on other modalities. An image-text multimodal neural language model can be used to retrieve images given complex sentence queries, retrieve phrase descriptions given image queries, as well as generate text conditioned on images. We show that in the case of image-text modelling we can jointly learn word representations and image features by training our models together with a convolutional network. Unlike many of the existing methods, our approach can generate sentence descriptions for images without the use of templates, structured prediction, and/or syntactic trees. While we focus on image-text modelling, our algorithms can be easily applied to other modalities such as audio.}
}

@inproceedings{bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@article{Zhu2018selfbleu,
archivePrefix = {arXiv},
arxivId = {1802.01886},
author = {Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
eprint = {1802.01886},
file = {::},
month = {feb},
title = {{Texygen: A Benchmarking Platform for Text Generation Models}},
url = {http://arxiv.org/abs/1802.01886},
year = {2018}
}

@inproceedings{lindh_generating_2018,
series = {Lecture {Notes} in {Computer} {Science}},
title = {Generating {Diverse} and {Meaningful} {Captions}},
isbn = {978-3-030-01418-6},
doi = {10.1007/978-3-030-01418-6_18},
language = {en},
booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2018},
publisher = {Springer International Publishing},
author = {Lindh, Annika and Ross, Robert J. and Mahalunkar, Abhijit and Salton, Giancarlo and Kelleher, John D.},
editor = {Kůrková, Věra and Manolopoulos, Yannis and Hammer, Barbara and Iliadis, Lazaros and Maglogiannis, Ilias},
year = {2018},
keywords = {Computer Vision, Contrastive Learning, Deep Learning, Diversity, Image Captioning, Image Retrieval, Machine Learning, MS COCO, Multimodal Training, Natural Language Generation, Natural Language Processing, Neural Networks, Specificity},
pages = {176--187}
}


@misc{devlin2015language,
    title={Language Models for Image Captioning: The Quirks and What Works},
    author={Jacob Devlin and Hao Cheng and Hao Fang and Saurabh Gupta and Li Deng and Xiaodong He and Geoffrey Zweig and Margaret Mitchell},
    year={2015},
    eprint={1505.01809},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@inproceedings{melas2019,
author = {Melas-Kyriazi, Luke and Rush, Alexander and Han, George},
doi = {10.18653/v1/d18-1084},
file = {:Users/xilini/work/gothenburg/literature/D18-1084.pdf:pdf},
title = {{Training for Diversity in Image Paragraph Captioning}},
year = {2019}
}

@article{selfcritical2016,
archivePrefix = {arXiv},
arxivId = {1612.00563},
author = {Rennie, Steven J. and Marcheret, Etienne and Mroueh, Youssef and Ross, Jarret and Goel, Vaibhava},
eprint = {1612.00563},
file = {::},
month = {dec},
title = {{Self-critical Sequence Training for Image Captioning}},
url = {https://arxiv.org/abs/1612.00563},
year = {2016}
}


@article{Lu2016,
archivePrefix = {arXiv},
arxivId = {1612.01887},
author = {Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},
eprint = {1612.01887},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Lu et al. - 2016 - Knowing When to Look Adaptive Attention via A Visual Sentinel for Image Captioning(2).pdf:pdf},
month = {dec},
title = {{Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning}},
url = {http://arxiv.org/abs/1612.01887},
year = {2016}
}

@article{Simonyan2014,
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556},
file = {::},
month = {sep},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2014}
}


@article{Xu2015,
archivePrefix = {arXiv},
arxivId = {1511.05234},
author = {Xu, Huijuan and Saenko, Kate},
eprint = {1511.05234},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Xu, Saenko - 2015 - Ask, Attend and Answer Exploring Question-Guided Spatial Attention for Visual Question Answering(2).pdf:pdf},
month = {nov},
title = {{Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering}},
url = {http://arxiv.org/abs/1511.05234},
year = {2015}
}

@InProceedings{meteor14,
  author    = {Michael Denkowski and Alon Lavie},
  title     = {Meteor Universal: Language Specific Translation Evaluation for Any Target Language},
  booktitle = {Proceedings of the EACL 2014 Workshop on Statistical Machine Translation},
  year      = {2014},
}


@misc{vedantam2014cider,
    title={CIDEr: Consensus-based Image Description Evaluation},
    author={Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
    year={2014},
    eprint={1411.5726},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{bleu2002,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}


@inproceedings{opennmt2017,
    title = "{O}pen{NMT}: Open-Source Toolkit for Neural Machine Translation",
    author = "Klein, Guillaume  and
      Kim, Yoon  and
      Deng, Yuntian  and
      Senellart, Jean  and
      Rush, Alexander",
    booktitle = "Proceedings of {ACL} 2017, System Demonstrations",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-4012",
    pages = "67--72",
}

@article{adam14,
author = {Kingma, Diederik and Ba, Jimmy},
year = {2014},
month = {12},
pages = {},
title = {Adam: A Method for Stochastic Optimization},
journal = {International Conference on Learning Representations}
}

@misc{luong2015effective,
    title={Effective Approaches to Attention-based Neural Machine Translation},
    author={Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
    year={2015},
    eprint={1508.04025},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{vqaLU16,
archivePrefix = {arXiv},
arxivId = {1606.00061},
author = {Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
eprint = {1606.00061},
file = {:Users/xilini/work/gothenburg/literature/1606.00061.pdf:pdf},
month = {may},
title = {{Hierarchical Question-Image Co-Attention for Visual Question Answering}},
url = {http://arxiv.org/abs/1606.00061},
year = {2016}
}

@inproceedings{Dobnik2016AMF,
  title={A Model for Attention-Driven Judgements in Type Theory with Records},
  author={Simon Dobnik and John D. Kelleher},
  year={2016}
}

@misc{Zarcone2016,
author = {Zarcone, Alessandra and van Schijndel, Marten and Vogels, Jorrig and Demberg, Vera},
booktitle = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2016.00844},
file = {:Users/xilini/work/gothenburg/literature/fpsyg-07-00844.pdf:pdf},
issn = {16641078},
keywords = {Attention,Goals,Language,Predictability,Predictive coding,Relevance,Salience,Surprisal},
title = {{Salience and attention in surprisal-based accounts of language processing}},
year = {2016}
}

@incollection{Ullman87,
  AUTHOR = {S. Ullman},
  TITLE = {Visual Routines},
  YEAR = 1987,
  BOOKTITLE = {Readings in Computer Vision: Issues, Problems, Principles, and Paradigms},
  EDITOR = {M. A. Fischler and O. Firschein},
  PUBLISHER = {Kaufmann},
  ADDRESS = {Los Altos, CA.},
  PAGES = {298-328},
  KEYWORDS = {vision}}
  


@article {Lavie04,
	Title = {Load theory of selective attention and cognitive control},
	Author = {Lavie, Nilli and Hirst, Aleksandra and de Fockert, Jan W and Viding, Essi},
	DOI = {10.1037/0096-3445.133.3.339},
	Number = {3},
	Volume = {133},
	Month = {September},
	Year = {2004},
	Journal = {Journal of experimental psychology. General},
	ISSN = {0096-3445},
	Pages = {339—354},
	URL = {https://doi.org/10.1037/0096-3445.133.3.339},
}




@article{Gatt2017,
archivePrefix = {arXiv},
arxivId = {1703.09902},
author = {Gatt, Albert and Krahmer, Emiel},
eprint = {1703.09902},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/Gatt, Krahmer - 2017 - Survey of the State of the Art in Natural Language Generation Core tasks, applications and evaluation.pdf:pdf},
month = {mar},
title = {{Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation}},
url = {https://arxiv.org/abs/1703.09902},
year = {2017}
}

@article{You2016,
archivePrefix = {arXiv},
arxivId = {1603.03925},
author = {You, Quanzeng and Jin, Hailin and Wang, Zhaowen and Fang, Chen and Luo, Jiebo},
eprint = {1603.03925},
file = {:Users/xilini/Library/Application Support/Mendeley Desktop/Downloaded/You et al. - 2016 - Image Captioning with Semantic Attention.pdf:pdf},
month = {mar},
title = {{Image Captioning with Semantic Attention}},
url = {https://arxiv.org/abs/1603.03925},
year = {2016}
}



@misc{vedantam2014cider,
    title={CIDEr: Consensus-based Image Description Evaluation},
    author={Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
    year={2014},
    eprint={1411.5726},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}


@misc{bernardi2016automatic,
    title={Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures},
    author={Raffaella Bernardi and Ruket Cakici and Desmond Elliott and Aykut Erdem and Erkut Erdem and Nazli Ikizler-Cinbis and Frank Keller and Adrian Muscat and Barbara Plank},
    year={2016},
    eprint={1601.03896},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{lin2014microsoft,
    title={Microsoft COCO: Common Objects in Context},
    author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
    year={2014},
    eprint={1405.0312},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{young-etal-2014-image,
    title = "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
    author = "Young, Peter  and
      Lai, Alice  and
      Hodosh, Micah  and
      Hockenmaier, Julia",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "2",
    year = "2014",
    url = "https://www.aclweb.org/anthology/Q14-1006",
    doi = "10.1162/tacl_a_00166",
    pages = "67--78",
    abstract = "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions.",
}

@misc{chen2015microsoft,
    title={Microsoft COCO Captions: Data Collection and Evaluation Server},
    author={Xinlei Chen and Hao Fang and Tsung-Yi Lin and Ramakrishna Vedantam and Saurabh Gupta and Piotr Dollar and C. Lawrence Zitnick},
    year={2015},
    eprint={1504.00325},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{krishnavisualgenome,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  year = {2016},
  url = {https://arxiv.org/abs/1602.07332},
}

@article{hodosh2013,
author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
title = {Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {853–899},
numpages = {47}
}

@misc{vinyals2014tell,
    title={Show and Tell: A Neural Image Caption Generator},
    author={Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan},
    year={2014},
    eprint={1411.4555},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{densecap,
  title={DenseCap: Fully Convolutional Localization Networks for Dense Captioning},
  author={Johnson, Justin and Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and 
             Pattern Recognition},
  year={2016}
}

@misc{holtzman2019curious,
    title={The Curious Case of Neural Text Degeneration},
    author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
    year={2019},
    eprint={1904.09751},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{barzilay-lee-2004-catching,
    title = "Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization",
    author = "Barzilay, Regina  and
      Lee, Lillian",
    booktitle = "Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004",
    month = may # " 2 - " # may # " 7",
    year = "2004",
    address = "Boston, Massachusetts, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N04-1015",
    pages = "113--120",
}


@misc{wang2019convolutional,
    title={Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation},
    author={Jing Wang and Yingwei Pan and Ting Yao and Jinhui Tang and Tao Mei},
    year={2019},
    eprint={1908.00249},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{liang2017recurrent,
    title={Recurrent Topic-Transition GAN for Visual Paragraph Generation},
    author={Xiaodan Liang and Zhiting Hu and Hao Zhang and Chuang Gan and Eric P. Xing},
    year={2017},
    eprint={1703.07022},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{Cooper08typetheory,
    author = {Robin Cooper},
    title = {Type theory with records and unification-based grammar},
    booktitle = {Logics for Linguistic Structures, pages 9 – 34. Mouton de Gruyter},
    year = {2008}
}

@inproceedings{chatterjee2018diverse,
Author = {Moitreya Chatterjee and Alexander G. Schwing},
Title = {Diverse and Coherent Paragraph Generation from Images},
Year = {2018},
booktitle = {ECCV},
}


@inproceedings{krause2016hierarchical,
  title={A Hierarchical Approach for Generating Descriptive Image Paragraphs},
  author={Krause, Jonathan and Johnson, Justin and Krishna, Ranjay and Fei-Fei, Li},
  booktitle={Computer Vision and Patterm Recognition (CVPR)},
  year={2017}
}

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{herdade2019image,
    title={Image Captioning: Transforming Objects into Words},
    author={Simao Herdade and Armin Kappeler and Kofi Boakye and Joao Soares},
    year={2019},
    eprint={1906.05963},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{anderson2017bottomup,
    title={Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
    author={Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},
    year={2017},
    eprint={1707.07998},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{lstm97,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}
  


@misc{bahdanau2014neural,
    title={Neural Machine Translation by Jointly Learning to Align and Translate},
    author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year={2014},
    eprint={1409.0473},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@misc{xu2015attend,
    title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
    author={Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio},
    year={2015},
    eprint={1502.03044},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@InProceedings{kiros14,
  title = 	 {Multimodal Neural Language Models},
  author = 	 {Ryan Kiros and Ruslan Salakhutdinov and Rich Zemel},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {595--603},
  year = 	 {2014},
  editor = 	 {Eric P. Xing and Tony Jebara},
  volume = 	 {32},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/kiros14.pdf},
  url = 	 {http://proceedings.mlr.press/v32/kiros14.html},
  abstract = 	 {We introduce two multimodal neural language models: models of natural language that can be conditioned on other modalities. An image-text multimodal neural language model can be used to retrieve images given complex sentence queries, retrieve phrase descriptions given image queries, as well as generate text conditioned on images. We show that in the case of image-text modelling we can jointly learn word representations and image features by training our models together with a convolutional network. Unlike many of the existing methods, our approach can generate sentence descriptions for images without the use of templates, structured prediction, and/or syntactic trees. While we focus on image-text modelling, our algorithms can be easily applied to other modalities such as audio.}
}
